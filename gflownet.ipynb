{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFN for music generation\n",
    "code reference: https://github.com/Tikquuss/GflowNets_Tutorial\n",
    "\n",
    "Reward function is of the form\n",
    "$$R(x\\mid y)=e^{-a*d(x,y)}$$\n",
    "where $x$ is a source image, $y$ is constructed by the GFN, and $d(x,y)$ denotes Eucledian distance. We start with a blank, black image (all zeros) and at each step the GFN chooses a pixel and colors it 1 or returns the STOP action.\n",
    "\n",
    "At each state, the actions are the set of all remaining coordinate pairs $[1,N]\\times[1,M]$ or the STOP action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import loadData\n",
    "songLen = 500\n",
    "\n",
    "data = loadData(songLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "M,N = songLen, config.MIDI_NOTE_RANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mlp(l, act=torch.nn.LeakyReLU(), tail=[]):\n",
    "    return torch.nn.Sequential(*(sum(\n",
    "        [[torch.nn.Linear(i, o)] + ([act] if n < len(l)-2 else [])\n",
    "         for n, (i, o) in enumerate(zip(l, l[1:]))], []) + tail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hid = 256\n",
    "n_layers = 2\n",
    "ndim = M*N\n",
    "input_dim = ndim # embedding dim\n",
    "output_dim = 2*ndim+1 # ndim + 1 for P_F (+1 for stop action) and ndim for P_B \n",
    "\n",
    "#For GAN, it is better to learn a Z for each image and not a global Z as there.\n",
    "independent_Z = False\n",
    "if independent_Z:\n",
    "    output_dim+=1\n",
    "    logZ_TB = 0\n",
    "    model_TB = make_mlp([input_dim] + [n_hid] * n_layers + [output_dim]).to(device)\n",
    "    optimizer = torch.optim.Adam([ {'params':model_TB.parameters(), 'lr':0.001}])\n",
    "else :\n",
    "    logZ_TB = torch.zeros((1,)).to(device) # log (initial state flow), Z = 1\n",
    "    model_TB = make_mlp([input_dim] + [n_hid] * n_layers + [output_dim]).to(device)\n",
    "    optimizer = torch.optim.Adam([ {'params':model_TB.parameters(), 'lr':0.001}, {'params':[logZ_TB], 'lr':0.1} ])\n",
    "    logZ_TB.requires_grad_()\n",
    "\n",
    "model_TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GFN hyperparams\n",
    "n_train_steps = 10000\n",
    "batch_size = 1\n",
    "uniform_PB = False\n",
    "minus_inf = -1e8\n",
    "\n",
    "a = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_TB = []\n",
    "rewards_TB = []\n",
    "logZ_TB_list = []\n",
    "all_visited_TB = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in tqdm.trange(n_train_steps):    \n",
    "    # TB loss for each trajectory\n",
    "    loss_TB = torch.zeros((batch_size,)).to(device)\n",
    "    loss_TB += 0 if independent_Z else logZ_TB # see the equation above\n",
    "    # finished trajectories\n",
    "    dones = torch.full((batch_size,), False, dtype=torch.bool).to(device)\n",
    "    # s_0\n",
    "    states = torch.zeros(size=(batch_size, ndim)).to(device) # (batch_size, ndim)\n",
    "    # actions chosen at each step \n",
    "    actions = None # (current_batch_size,)\n",
    "\n",
    "    max_steps = 1e8 #ndim+0\n",
    "    i = 0\n",
    "    while torch.any(~dones) and i <= max_steps :\n",
    "        ### Forward pass ### \n",
    "        current_batch_size = (~dones).sum()\n",
    "        non_terminal_states = states[~dones] # (current_batch_size, ndim)\n",
    "        logits = model_TB(non_terminal_states) # (current_batch_size, output_dim)\n",
    "\n",
    "        ### Backward Policy ### \n",
    "        PB_logits = logits[...,ndim+1:2*ndim+1] # (current_batch_size, ndim)\n",
    "        PB_logits = PB_logits * (0 if uniform_PB else 1) # (current_batch_size, ndim)\n",
    "        # Cells that are still black (0) are excluded from the action space of the backward policy\n",
    "        PB_mask = (non_terminal_states == 0.).float() # (current_batch_size, ndim)\n",
    "        logPB = (PB_logits + minus_inf*PB_mask).log_softmax(1) # (current_batch_size, ndim)\n",
    "        if actions is not None: \n",
    "            loss_TB[~dones] -= logPB.gather(1, actions[actions!=ndim].unsqueeze(1)).squeeze(1)\n",
    "        elif independent_Z :\n",
    "            logZ_TB = logits[...,-1]\n",
    "            loss_TB += logZ_TB + 0 \n",
    "            logZ_TB = logZ_TB.mean()\n",
    "\n",
    "        ### Forward Policy ### \n",
    "        PF_logits = logits[...,:ndim+1] # (current_batch_size, ndim+1) \n",
    "        # Cells that are already white (1) are excluded from the action space of the forward policy\n",
    "        edge_mask = (non_terminal_states == 1.).float() # (current_batch_size, ndim)\n",
    "        stop_action_mask = torch.zeros((current_batch_size, 1), device=device) # (current_batch_size, 1)\n",
    "        PF_mask = torch.cat([edge_mask, stop_action_mask], 1) # (current_batch_size, ndim+1)\n",
    "        logPF = (PF_logits + minus_inf*PF_mask).log_softmax(1) # (current_batch_size, ndim+1)\n",
    "        sample_temperature = 1\n",
    "        sample_ins_probs = (logPF/sample_temperature).softmax(1) # (current_batch_size, ndim+1)\n",
    "        actions = sample_ins_probs.multinomial(1) # (current_batch_size,)\n",
    "        loss_TB[~dones] += logPF.gather(1, actions).squeeze(1)\n",
    "\n",
    "        ### select terminal states ### \n",
    "        terminates = (actions==ndim).squeeze(1)\n",
    "        for state in non_terminal_states[terminates]: \n",
    "            all_visited_TB.append(state)\n",
    "       \n",
    "       # Update dones\n",
    "        dones[~dones] |= terminates\n",
    "\n",
    "        # Update non completed trajectories\n",
    "        with torch.no_grad():\n",
    "            non_terminates = actions[~terminates].squeeze()\n",
    "            tmp = states[~dones]\n",
    "            tmp[torch.arange((~dones).sum()), non_terminates] = 1.\n",
    "            states[~dones] = tmp\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "    dist = torch.nn.functional.mse_loss(input=states.view(M,N), target=x.view(M,N))\n",
    "    R = (-a*dist).exp()\n",
    "    loss_TB -= R.log()\n",
    "    loss = (loss_TB**2).sum()/batch_size\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses_TB.append(loss.item())\n",
    "    rewards_TB.append(R.mean().cpu())\n",
    "    logZ_TB_list.append(logZ_TB.item())\n",
    "\n",
    "    if it%100==0: \n",
    "        print('\\nloss =', np.array(losses_TB[-1:]).mean(), 'logZ =', logZ_TB.item(), \"R =\", np.array(rewards_TB[-1:]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./trained_gfn_model/model_TB.pkl\", \"wb\") as f:\n",
    "    pkl.dump(model_TB, f)\n",
    "with open(\"./trained_gfn_model/losses_TB.pkl\", \"wb\") as f:\n",
    "    pkl.dump(losses_TB, f)\n",
    "with open(\"./trained_gfn_model/rewards_TB.pkl\", \"wb\") as f:\n",
    "    pkl.dump(rewards_TB, f)\n",
    "with open(\"./trained_gfn_model/logZ_TB_list.pkl\", \"wb\") as f:\n",
    "    pkl.dump(logZ_TB_list, f)\n",
    "with open(\"./trained_gfn_model/all_visited_TB.pkl\", \"wb\") as f:\n",
    "    pkl.dump(all_visited_TB, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f83d49ec2e377ff593a7e1f57e0bf435ba6c21cc1cd7298abcfa9e9cf3e4623f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
